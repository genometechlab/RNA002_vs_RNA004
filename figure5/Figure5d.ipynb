{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d69df9-0d7e-4f5b-85bd-dd87804389e2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866ec801-d136-4d5b-8c8a-79fcaac12fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 Helvetica fonts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Set, Tuple, Optional\n",
    "\n",
    "# Try custom plotting style\n",
    "try:\n",
    "    from genometechlab_plotting import setup_style, get_colors\n",
    "    setup_style('inline')\n",
    "    HAS_CUSTOM_STYLE = True\n",
    "except ImportError:\n",
    "    HAS_CUSTOM_STYLE = False\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Try IntervalTree for overlap detection\n",
    "try:\n",
    "    from intervaltree import IntervalTree\n",
    "    HAS_INTERVALTREE = True\n",
    "except ImportError:\n",
    "    print(\"IntervalTree not available - overlap detection disabled\")\n",
    "    HAS_INTERVALTREE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6fc5c-6891-4324-9f31-0f6e846929ed",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f05edeb-f426-4912-8055-b92a9862af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gtf_attributes(attributes_string):\n",
    "    \"\"\"Parse GTF attribute string\"\"\"\n",
    "    attributes = {}\n",
    "    for pair in attributes_string.strip().split(';'):\n",
    "        if not pair.strip():\n",
    "            continue\n",
    "        parts = pair.strip().split(' ', 1)\n",
    "        if len(parts) == 2:\n",
    "            key, value = parts\n",
    "            attributes[key] = value.strip('\"')\n",
    "    return attributes\n",
    "\n",
    "def gencode_slop(g_slop):\n",
    "    \"\"\"Parse GENCODE GTF attributes\"\"\"\n",
    "    attrs = parse_gtf_attributes(g_slop)\n",
    "    exon_num = attrs.get('exon_number')\n",
    "    iso_name = attrs.get('transcript_name', '')\n",
    "    \n",
    "    if exon_num:\n",
    "        try:\n",
    "            exon_num = int(exon_num)\n",
    "        except:\n",
    "            exon_num = None\n",
    "    \n",
    "    return iso_name, exon_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a3abd-33e5-4c3f-ab9f-e7beaf14c116",
   "metadata": {},
   "source": [
    "## Transcript Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7d0b0d-8b01-40c6-a408-ef8266c58139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_transcripts_to_filter(gtf_path, config):\n",
    "    \"\"\"Identify transcripts to filter based on configuration\"\"\"\n",
    "    if not gtf_path.exists():\n",
    "        raise FileNotFoundError(f\"GTF file not found: {gtf_path}\")\n",
    "    \n",
    "    print(\"Identifying transcripts to filter...\")\n",
    "    \n",
    "    filtered = defaultdict(set)\n",
    "    \n",
    "    if HAS_INTERVALTREE:\n",
    "        chrom_intervals = defaultdict(IntervalTree)\n",
    "        gene_to_intervals = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    transcript_to_gene_biotype = {}\n",
    "    transcript_tags = defaultdict(set)\n",
    "    transcript_support_level = {}\n",
    "    transcript_biotypes = {}\n",
    "    gene_biotypes = {}\n",
    "    zero_width_count = 0\n",
    "    \n",
    "    # First pass: collect information\n",
    "    with open(gtf_path, 'r') as infile:\n",
    "        for line in tqdm(infile, desc=\"Reading GTF\"):\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            \n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 9:\n",
    "                continue\n",
    "            \n",
    "            feature_type = fields[2]\n",
    "            attrs = parse_gtf_attributes(fields[8])\n",
    "            \n",
    "            gene_id = attrs.get('gene_id')\n",
    "            gene_name = attrs.get('gene_name')\n",
    "            gene_biotype = attrs.get('gene_biotype', attrs.get('gene_type', 'unknown'))\n",
    "            transcript_id = attrs.get('transcript_id')\n",
    "            transcript_biotype = attrs.get('transcript_biotype', attrs.get('transcript_type', 'unknown'))\n",
    "            \n",
    "            if gene_id and gene_biotype:\n",
    "                gene_biotypes[gene_id] = gene_biotype\n",
    "            \n",
    "            if transcript_id:\n",
    "                if transcript_biotype:\n",
    "                    transcript_biotypes[transcript_id] = transcript_biotype\n",
    "                \n",
    "                if gene_biotype:\n",
    "                    transcript_to_gene_biotype[transcript_id] = gene_biotype\n",
    "                \n",
    "                if 'tag' in attrs:\n",
    "                    tags = attrs['tag'].split(',') if ',' in attrs['tag'] else [attrs['tag']]\n",
    "                    transcript_tags[transcript_id].update(tags)\n",
    "                \n",
    "                if 'transcript_support_level' in attrs:\n",
    "                    tsl = attrs['transcript_support_level']\n",
    "                    if tsl != 'NA':\n",
    "                        try:\n",
    "                            transcript_support_level[transcript_id] = int(tsl.replace('tsl', ''))\n",
    "                        except:\n",
    "                            pass\n",
    "            \n",
    "            if HAS_INTERVALTREE and config.get('filter_overlaps', True):\n",
    "                if feature_type in [\"gene\", \"exon\", \"CDS\", \"transcript\"]:\n",
    "                    chrom = fields[0]\n",
    "                    start = int(fields[3])\n",
    "                    end = int(fields[4])\n",
    "                    \n",
    "                    if start >= end:\n",
    "                        zero_width_count += 1\n",
    "                        continue\n",
    "                    \n",
    "                    if gene_name:\n",
    "                        chrom_intervals[chrom][start:end] = gene_name\n",
    "                        gene_to_intervals[gene_name][chrom].append((start, end))\n",
    "    \n",
    "    if zero_width_count > 0:\n",
    "        print(f\"Skipped {zero_width_count} zero-width intervals\")\n",
    "    \n",
    "    # Apply filters\n",
    "    print(\"Applying biotype filters...\")\n",
    "    \n",
    "    allowed_gene_biotypes = set(config.get('allowed_gene_biotypes', ['protein_coding']))\n",
    "    for transcript_id, gene_biotype in transcript_to_gene_biotype.items():\n",
    "        if gene_biotype not in allowed_gene_biotypes:\n",
    "            filtered['non_protein_coding_gene'].add(transcript_id)\n",
    "    \n",
    "    allowed_transcript_biotypes = set(config.get('allowed_transcript_biotypes', ['protein_coding']))\n",
    "    for transcript_id, transcript_biotype in transcript_biotypes.items():\n",
    "        if transcript_biotype not in allowed_transcript_biotypes:\n",
    "            filtered['non_protein_coding_transcript'].add(transcript_id)\n",
    "    \n",
    "    if config.get('filter_retained_introns', True):\n",
    "        for transcript_id, tags in transcript_tags.items():\n",
    "            if 'retained_intron' in tags:\n",
    "                filtered['retained_intron'].add(transcript_id)\n",
    "    \n",
    "    if config.get('filter_readthrough', True):\n",
    "        for transcript_id, tags in transcript_tags.items():\n",
    "            if 'readthrough_transcript' in tags:\n",
    "                filtered['readthrough'].add(transcript_id)\n",
    "    \n",
    "    if config.get('filter_nmd', True):\n",
    "        for transcript_id, tags in transcript_tags.items():\n",
    "            if 'nonsense_mediated_decay' in tags or 'NMD' in tags:\n",
    "                filtered['nmd'].add(transcript_id)\n",
    "    \n",
    "    if config.get('filter_non_canonical', False):\n",
    "        for transcript_id, tags in transcript_tags.items():\n",
    "            if not ('canonical' in tags or 'basic' in tags or 'MANE_Select' in tags):\n",
    "                filtered['non_canonical'].add(transcript_id)\n",
    "    \n",
    "    min_tsl = config.get('min_transcript_support_level')\n",
    "    if min_tsl is not None:\n",
    "        for transcript_id in transcript_biotypes:\n",
    "            tsl = transcript_support_level.get(transcript_id, 999)\n",
    "            if tsl > min_tsl:\n",
    "                filtered['low_support'].add(transcript_id)\n",
    "    \n",
    "    # Find overlapping genes\n",
    "    if HAS_INTERVALTREE and config.get('filter_overlaps', True):\n",
    "        overlapping_genes = set()\n",
    "        genes_checked = set()\n",
    "        \n",
    "        for gene_name, chrom_dict in gene_to_intervals.items():\n",
    "            if gene_name in genes_checked:\n",
    "                continue\n",
    "            genes_checked.add(gene_name)\n",
    "            \n",
    "            for chrom, intervals in chrom_dict.items():\n",
    "                for start, end in intervals:\n",
    "                    overlaps = chrom_intervals[chrom][start:end]\n",
    "                    overlapping_gene_names = set(overlap.data for overlap in overlaps)\n",
    "                    \n",
    "                    if len(overlapping_gene_names) > 1:\n",
    "                        overlapping_genes.update(overlapping_gene_names)\n",
    "        \n",
    "        with open(gtf_path, 'r') as infile:\n",
    "            for line in infile:\n",
    "                if line.startswith(\"#\"):\n",
    "                    continue\n",
    "                \n",
    "                fields = line.strip().split('\\t')\n",
    "                if len(fields) < 9:\n",
    "                    continue\n",
    "                \n",
    "                attrs = parse_gtf_attributes(fields[8])\n",
    "                gene_name = attrs.get('gene_name')\n",
    "                transcript_id = attrs.get('transcript_id')\n",
    "                \n",
    "                if gene_name in overlapping_genes and transcript_id:\n",
    "                    filtered['overlapping_gene'].add(transcript_id)\n",
    "    \n",
    "    # Map transcript names to IDs\n",
    "    transcript_name_to_id = {}\n",
    "    with open(gtf_path, 'r') as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 9:\n",
    "                continue\n",
    "            attrs = parse_gtf_attributes(fields[8])\n",
    "            transcript_id = attrs.get('transcript_id')\n",
    "            transcript_name = attrs.get('transcript_name')\n",
    "            if transcript_id and transcript_name:\n",
    "                transcript_name_to_id[transcript_name] = transcript_id\n",
    "    \n",
    "    final_filtered = defaultdict(set)\n",
    "    for reason, transcript_ids in filtered.items():\n",
    "        final_filtered[reason].update(transcript_ids)\n",
    "        for transcript_id in transcript_ids:\n",
    "            for name, tid in transcript_name_to_id.items():\n",
    "                if tid == transcript_id:\n",
    "                    final_filtered[reason].add(name)\n",
    "    \n",
    "    print(\"\\nFiltering summary:\")\n",
    "    total_filtered = set()\n",
    "    for reason, items in final_filtered.items():\n",
    "        print(f\"  {reason}: {len(items):,} transcripts\")\n",
    "        total_filtered.update(items)\n",
    "    print(f\"  Total unique items to filter: {len(total_filtered):,}\")\n",
    "    \n",
    "    return final_filtered, total_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6050f2b6-1f35-4b0b-afd6-28e9db790487",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe62a268-1e77-4df9-a213-5df7126b8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_df_by_chrom_and_coords(df, chrom, start, stop, codon_start, codon_stop):\n",
    "    \"\"\"Calculate positions relative to start codon\"\"\"\n",
    "    tmp_df = df.filter(\n",
    "        (pl.col(\"Chromosome\") == chrom) & \n",
    "        (pl.col(\"Start\") >= start) & \n",
    "        (pl.col(\"Start\") + 1 <= stop)\n",
    "    )\n",
    "    positions = tmp_df[\"Start\"].to_list()\n",
    "    return [pos - codon_stop if pos > codon_stop else pos - codon_start for pos in positions]\n",
    "\n",
    "def load_parquet_files(directory_path):\n",
    "    \"\"\"Load parquet files and infer modification types\"\"\"\n",
    "    directory_path = Path(directory_path)\n",
    "    \n",
    "    if not directory_path.exists():\n",
    "        raise ValueError(f\"Directory not found: {directory_path}\")\n",
    "    \n",
    "    if not directory_path.is_dir():\n",
    "        raise ValueError(f\"Path is not a directory: {directory_path}\")\n",
    "    \n",
    "    parquet_files = sorted(directory_path.glob('*.parquet'))\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in directory: {directory_path}\")\n",
    "    \n",
    "    print(f\"\\nLoading {len(parquet_files)} parquet file(s)...\")\n",
    "    \n",
    "    code_mappings = {\n",
    "        '17596': 'Ino',\n",
    "        '17802': 'Psi',\n",
    "        '19227': '2OmethylU',\n",
    "        '19228': '2OmethylC',\n",
    "        '19229': '2OmethylG',\n",
    "        '69426': '2OmethylA',\n",
    "    }\n",
    "    letter_codes = {'a': 'm6A', 'm': 'm5C'}\n",
    "    \n",
    "    df_dict = {}\n",
    "    \n",
    "    for parquet_path in parquet_files:\n",
    "        filename = parquet_path.stem\n",
    "        \n",
    "        mod_type = None\n",
    "        for code, mt in code_mappings.items():\n",
    "            if code in filename:\n",
    "                mod_type = mt\n",
    "                break\n",
    "        if mod_type is None:\n",
    "            for letter, mt in letter_codes.items():\n",
    "                if f'_{letter}_' in filename or filename.endswith(f'_{letter}'):\n",
    "                    mod_type = mt\n",
    "                    break\n",
    "        \n",
    "        if mod_type is None:\n",
    "            print(f\"  Skipping {parquet_path.name}: could not infer modification type\")\n",
    "            continue\n",
    "        \n",
    "        df = pl.read_parquet(parquet_path)\n",
    "        \n",
    "        if 'Chromosome' not in df.columns or 'Start' not in df.columns:\n",
    "            print(f\"  Skipping {parquet_path.name}: missing required columns\")\n",
    "            continue\n",
    "        \n",
    "        if mod_type in df_dict:\n",
    "            df_dict[mod_type] = pl.concat([df_dict[mod_type], df])\n",
    "        else:\n",
    "            df_dict[mod_type] = df\n",
    "        \n",
    "        print(f\"  Loaded {parquet_path.name} -> {mod_type}: {len(df):,} rows\")\n",
    "    \n",
    "    print(f\"\\nLoaded {len(df_dict)} modification type(s): {list(df_dict.keys())}\")\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c032bb-b5b5-4051-805a-7ae8d821c181",
   "metadata": {},
   "source": [
    "## GTF Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4309d792-dd07-4dc8-8d1d-4427c69493b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gtf_and_calculate_positions(df_dict, gtf_path, config):\n",
    "    \"\"\"Process GTF with filtering and calculate positions relative to start codons\"\"\"\n",
    "    print(f\"\\nParsing GTF file: {gtf_path}\")\n",
    "    \n",
    "    filtered_transcripts, all_filtered = identify_transcripts_to_filter(gtf_path, config)\n",
    "    \n",
    "    exon_num_to_coords = defaultdict(dict)\n",
    "    start_codon_to_exon_num = defaultdict(int)\n",
    "    transcript_to_gene = {}\n",
    "    \n",
    "    transcripts_loaded = 0\n",
    "    start_codons_loaded = 0\n",
    "    transcripts_skipped = 0\n",
    "    \n",
    "    with open(gtf_path, 'r') as infile:\n",
    "        for line in tqdm(infile, desc=\"Reading GTF\"):\n",
    "            if line[0] == \"#\":\n",
    "                continue\n",
    "            split_line = line.strip().split('\\t')\n",
    "            \n",
    "            attrs = parse_gtf_attributes(split_line[8])\n",
    "            transcript_id = attrs.get('transcript_id')\n",
    "            transcript_name = attrs.get('transcript_name')\n",
    "            gene_name = attrs.get('gene_name', '')\n",
    "            \n",
    "            if transcript_id and transcript_id in all_filtered:\n",
    "                transcripts_skipped += 1\n",
    "                continue\n",
    "            if transcript_name and transcript_name in all_filtered:\n",
    "                transcripts_skipped += 1\n",
    "                continue\n",
    "            \n",
    "            if transcript_name and gene_name:\n",
    "                transcript_to_gene[transcript_name] = gene_name\n",
    "            \n",
    "            if split_line[2] == \"exon\":\n",
    "                iso_name, exon_num = gencode_slop(split_line[8])\n",
    "                if iso_name and exon_num:\n",
    "                    if iso_name not in exon_num_to_coords:\n",
    "                        transcripts_loaded += 1\n",
    "                    exon_num_to_coords[iso_name][exon_num] = (int(split_line[3]), int(split_line[4]))\n",
    "            \n",
    "            if split_line[2] == \"start_codon\":\n",
    "                chrom = split_line[0]\n",
    "                start, stop = (int(split_line[3]), int(split_line[4]))\n",
    "                iso_name, exon_num = gencode_slop(split_line[8])\n",
    "                if iso_name and exon_num:\n",
    "                    start_codon_to_exon_num[(chrom, start, stop, iso_name)] = exon_num\n",
    "                    start_codons_loaded += 1\n",
    "    \n",
    "    print(f\"Loaded {transcripts_loaded:,} transcripts (skipped {transcripts_skipped:,})\")\n",
    "    print(f\"Found {start_codons_loaded:,} start codons\")\n",
    "    print(f\"Unique genes: {len(set(transcript_to_gene.values())):,}\")\n",
    "    \n",
    "    print(\"\\nFiltering breakdown:\")\n",
    "    for reason, items in filtered_transcripts.items():\n",
    "        print(f\"  {reason}: {len(items):,}\")\n",
    "    \n",
    "    print(\"\\nCalculating positions relative to start codons...\")\n",
    "    results = {}\n",
    "    \n",
    "    for mod_type, df in df_dict.items():\n",
    "        print(f\"  Processing {mod_type}...\")\n",
    "        positions = []\n",
    "        \n",
    "        for key in tqdm(start_codon_to_exon_num.keys(), desc=f\"    {mod_type}\"):\n",
    "            chrom, start, stop, iso_name = key\n",
    "            exon_num = start_codon_to_exon_num[key]\n",
    "            if exon_num not in exon_num_to_coords[iso_name]:\n",
    "                continue\n",
    "            slice_start, slice_stop = exon_num_to_coords[iso_name][exon_num]\n",
    "            positions.extend(slice_df_by_chrom_and_coords(df, chrom, slice_start, slice_stop, start, stop))\n",
    "        \n",
    "        results[mod_type] = positions\n",
    "        print(f\"    Found {len(positions):,} positions\")\n",
    "    \n",
    "    stats = {\n",
    "        'transcripts_loaded': transcripts_loaded,\n",
    "        'transcripts_skipped': transcripts_skipped,\n",
    "        'start_codons_analyzed': start_codons_loaded,\n",
    "        'unique_genes': len(set(transcript_to_gene.values())),\n",
    "        'filtering_breakdown': {k: len(v) for k, v in filtered_transcripts.items()}\n",
    "    }\n",
    "    \n",
    "    return results, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0405638-f5a5-43e1-812a-92289b80202e",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad2f87f-f831-48b6-9e7d-93bd05dc6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modification_colors(mod_names):\n",
    "    \"\"\"Get colors for modifications\"\"\"\n",
    "    colors = {}\n",
    "    \n",
    "    default_colors = {\n",
    "        'm5C': '#2ca02c',\n",
    "        'm6A': '#1f77b4',\n",
    "        'Ino': '#ff7f0e',\n",
    "        'Psi': '#d62728',\n",
    "        '2OmethylA': '#9467bd',\n",
    "        '2OmethylC': '#8c564b',\n",
    "        '2OmethylG': '#e377c2',\n",
    "        '2OmethylU': '#7f7f7f',\n",
    "    }\n",
    "    \n",
    "    if HAS_CUSTOM_STYLE:\n",
    "        try:\n",
    "            for i, mod_name in enumerate(mod_names):\n",
    "                color = get_colors(i)\n",
    "                if isinstance(color, str) and (color.startswith('#') or color in plt.colors.CSS4_COLORS):\n",
    "                    colors[mod_name] = color\n",
    "                elif isinstance(color, (list, tuple)) and len(color) >= 3:\n",
    "                    colors[mod_name] = tuple(float(c) for c in color[:4])\n",
    "                else:\n",
    "                    colors[mod_name] = default_colors.get(mod_name, f'C{i}')\n",
    "        except Exception as e:\n",
    "            print(f\"Could not use custom colors: {e}\")\n",
    "            colors = default_colors\n",
    "    else:\n",
    "        colors = default_colors\n",
    "    \n",
    "    return colors\n",
    "\n",
    "def plot_modifications(results, output_path='rna_modifications_plot.pdf', \n",
    "                       window_size=200, bin_width=100, y_limit=None,\n",
    "                       figure_size=(10, 2.5), show_kde=True, y_axis_mode='dynamic',\n",
    "                       stats=None, save_plot=True):\n",
    "    \"\"\"Create figure with modification distributions\"\"\"\n",
    "    \n",
    "    results_filtered = {k: v for k, v in results.items() if len(v) > 0}\n",
    "    \n",
    "    if not results_filtered:\n",
    "        print(\"No modifications found to plot!\")\n",
    "        return\n",
    "    \n",
    "    colors = get_modification_colors(list(results_filtered.keys()))\n",
    "    \n",
    "    n_mods = len(results_filtered)\n",
    "    fig, axes = plt.subplots(n_mods, 1, \n",
    "                             figsize=(figure_size[0], figure_size[1] * n_mods),\n",
    "                             sharex=True, sharey=(y_axis_mode == 'shared'))\n",
    "    \n",
    "    if n_mods == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    plotted_ylims = {}\n",
    "    \n",
    "    for ax, (mod_name, positions) in zip(axes, results_filtered.items()):\n",
    "        positions_array = np.array(positions)\n",
    "        filtered_pos = [x for x in positions_array if -window_size <= x <= window_size]\n",
    "        \n",
    "        print(f\"{mod_name}: {len(filtered_pos):,} modifications in window\")\n",
    "        \n",
    "        if len(filtered_pos) > 0:\n",
    "            color = colors[mod_name]\n",
    "            \n",
    "            sns.histplot(\n",
    "                filtered_pos,\n",
    "                ax=ax,\n",
    "                discrete=True,\n",
    "                color=color,\n",
    "                label=mod_name,\n",
    "                kde=show_kde,\n",
    "                kde_kws={'clip': (-window_size, window_size), 'bw_adjust': 0.5} if show_kde else None,\n",
    "                stat=\"density\",\n",
    "                binwidth=bin_width,\n",
    "                linewidth=0.2,\n",
    "                element=\"step\",\n",
    "                fill=False\n",
    "            )\n",
    "            \n",
    "            ax.axvline(x=0, color='black', linestyle='dashdot', linewidth=0.2)\n",
    "            plotted_ylims[mod_name] = ax.get_ylim()\n",
    "        \n",
    "        ax.grid(False)\n",
    "        ax.legend(loc='upper right')\n",
    "    \n",
    "    if y_limit is None and y_axis_mode != 'dynamic':\n",
    "        if y_axis_mode == 'shared':\n",
    "            if plotted_ylims:\n",
    "                max_ylim = max([ylim[1] for ylim in plotted_ylims.values()])\n",
    "                for ax in axes:\n",
    "                    ax.set_ylim(0, max_ylim)\n",
    "        \n",
    "        elif y_axis_mode == 'grouped':\n",
    "            high_density_mods = ['m6A', 'Ino', 'Psi']\n",
    "            high_density_ylims = [plotted_ylims[m][1] for m in high_density_mods if m in plotted_ylims]\n",
    "            if high_density_ylims:\n",
    "                high_density_max = max(high_density_ylims)\n",
    "                for ax, (mod_name, _) in zip(axes, results_filtered.items()):\n",
    "                    if mod_name in high_density_mods:\n",
    "                        ax.set_ylim(0, high_density_max)\n",
    "    \n",
    "    elif y_limit is not None:\n",
    "        for ax in axes:\n",
    "            ax.set_ylim([0, y_limit])\n",
    "    \n",
    "    if stats:\n",
    "        title = (f'RNA Modifications Relative to Start Codons\\n'\n",
    "                f'({stats[\"unique_genes\"]:,} genes, {stats[\"start_codons_analyzed\"]:,} start codons)')\n",
    "    else:\n",
    "        title = 'RNA Modifications Relative to Start Codons'\n",
    "    \n",
    "    if ax == axes[0]:\n",
    "        axes[0].set_title(title, fontsize=12, fontweight='bold', pad=10)\n",
    "    \n",
    "    axes[-1].set_xlabel('Position relative to start codon (bp)', fontsize=11)\n",
    "    axes[-1].set_xlim([-window_size, window_size])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plot:\n",
    "        output_path = Path(output_path)\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\nFigure saved to {output_path}\")\n",
    "        \n",
    "        png_path = output_path.with_suffix('.png')\n",
    "        fig.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"PNG version saved to {png_path}\")\n",
    "    else:\n",
    "        print(\"\\nDisplaying plot (not saved)\")\n",
    "        plt.show()\n",
    "    \n",
    "    if save_plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3093c85d-5af0-4f3e-b46a-a72fc2d3529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined(results, output_path='rna_modifications_combined.pdf',\n",
    "                 window_size=200, bin_width=100, stats=None, save_plot=True):\n",
    "    \"\"\"Create a single plot with all modifications overlaid\"\"\"\n",
    "    \n",
    "    results_filtered = {k: v for k, v in results.items() if len(v) > 0}\n",
    "    \n",
    "    if not results_filtered:\n",
    "        print(\"No modifications found to plot!\")\n",
    "        return\n",
    "    \n",
    "    colors = get_modification_colors(list(results_filtered.keys()))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    for mod_name, positions in results_filtered.items():\n",
    "        positions_array = np.array(positions)\n",
    "        filtered_pos = [x for x in positions_array if -window_size <= x <= window_size]\n",
    "        \n",
    "        if len(filtered_pos) > 0:\n",
    "            color = colors[mod_name]\n",
    "            \n",
    "            sns.histplot(\n",
    "                filtered_pos,\n",
    "                ax=ax,\n",
    "                discrete=True,\n",
    "                color=color,\n",
    "                label=f'{mod_name} (n={len(filtered_pos):,})',\n",
    "                kde=True,\n",
    "                kde_kws={'clip': (-window_size, window_size), 'bw_adjust': 0.5},\n",
    "                stat=\"density\",\n",
    "                binwidth=bin_width,\n",
    "                linewidth=0.2,\n",
    "                element=\"step\",\n",
    "                fill=False,\n",
    "                alpha=0.7\n",
    "            )\n",
    "    \n",
    "    ax.axvline(x=0, color='black', linestyle='dashdot', linewidth=0.2)\n",
    "    \n",
    "    ax.set_xlabel('Position relative to start codon (bp)', fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    \n",
    "    if stats:\n",
    "        title = (f'RNA Modifications Relative to Start Codons\\n'\n",
    "                f'({stats[\"unique_genes\"]:,} genes, {stats[\"start_codons_analyzed\"]:,} start codons)')\n",
    "    else:\n",
    "        title = 'RNA Modifications Relative to Start Codons'\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=10)\n",
    "    ax.legend(loc='upper right', frameon=True, fontsize=10)\n",
    "    ax.grid(False)\n",
    "    ax.set_xlim([-window_size, window_size])\n",
    "    \n",
    "    if save_plot:\n",
    "        output_path = Path(output_path)\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Combined figure saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"Displaying combined plot (not saved)\")\n",
    "        plt.show()\n",
    "    \n",
    "    if save_plot:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cb475-6d86-4c1b-94fd-48002fd709a3",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9056f45-b4fd-476a-ab77-41c78de75775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(results, stats=None):\n",
    "    \"\"\"Print summary statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODIFICATION ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if stats:\n",
    "        print(\"\\nFiltering Statistics:\")\n",
    "        print(f\"  Transcripts retained: {stats['transcripts_loaded']:,}\")\n",
    "        print(f\"  Transcripts filtered: {stats['transcripts_skipped']:,}\")\n",
    "        print(f\"  Start codons analyzed: {stats['start_codons_analyzed']:,}\")\n",
    "        print(f\"  Unique genes: {stats['unique_genes']:,}\")\n",
    "        \n",
    "        if 'filtering_breakdown' in stats:\n",
    "            print(\"\\nFiltering breakdown:\")\n",
    "            for reason, count in stats['filtering_breakdown'].items():\n",
    "                print(f\"    {reason}: {count:,}\")\n",
    "    \n",
    "    print(\"\\nModification Counts Near Start Codons:\")\n",
    "    total = 0\n",
    "    for mod_name, positions in results.items():\n",
    "        count = len(positions)\n",
    "        total += count\n",
    "        print(f\"  {mod_name}: {count:,} modifications\")\n",
    "        \n",
    "        if count > 0:\n",
    "            pos_array = np.array(positions)\n",
    "            print(f\"    Range: [{pos_array.min()}, {pos_array.max()}] bp\")\n",
    "            print(f\"    Within ±100bp: {np.sum(np.abs(pos_array) <= 100):,}\")\n",
    "            print(f\"    Within ±50bp: {np.sum(np.abs(pos_array) <= 50):,}\")\n",
    "    \n",
    "    print(f\"\\n  Total: {total:,} modifications\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def save_results(results, output_path, stats=None):\n",
    "    \"\"\"Save results to pickle file\"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    save_dict = {'results': results}\n",
    "    if stats:\n",
    "        save_dict['stats'] = stats\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(save_dict, f)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "\n",
    "def load_results(pickle_path):\n",
    "    \"\"\"Load results from pickle file\"\"\"\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Loaded results from {pickle_path}\")\n",
    "    \n",
    "    if isinstance(data, dict) and 'results' in data:\n",
    "        return data['results'], data.get('stats', None)\n",
    "    else:\n",
    "        return data, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6c253-0e62-4c6b-b98d-c0f91081c342",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29e6670-74f1-429e-8234-86ea52437327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GTF File if not local:\n",
    "GTF_FILE_GZ = './gencode.v47.annotation.gtf.gz'\n",
    "\n",
    "if not os.path.exists(GTF_FILE_GZ):\n",
    "    print(\"Downloading GTF file...\")\n",
    "    subprocess.run(['wget', '-q', '-O', GTF_FILE_GZ, \n",
    "                    'https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_47/gencode.v47.annotation.gtf.gz'])\n",
    "    print(f\"  Downloaded to {GTF_FILE_GZ}\")\n",
    "\n",
    "GTF_FILE = GTF_FILE_GZ[:-3]  # Remove .gz extension\n",
    "\n",
    "if not os.path.exists(GTF_FILE):\n",
    "    print(\"Decompressing GTF file...\")\n",
    "    subprocess.run(['gunzip', '-k', GTF_FILE_GZ])  # -k keeps the original\n",
    "    print(f\"  Decompressed to {GTF_FILE}\")\n",
    "\n",
    "# Set your paths here\n",
    "PARQUET_DIR = Path('../Exemplar_Data/parquet_files/')  # Directory containing parquet files\n",
    "GTF_PATH = Path(f'{GTF_FILE}')\n",
    "OUTPUT_DIR = Path('./')  # Output directory\n",
    "\n",
    "# Plotting parameters\n",
    "WINDOW_SIZE = 200  # Window around start codon (bp)\n",
    "BIN_WIDTH = 100    # Histogram bin width\n",
    "Y_AXIS_MODE = 'dynamic'  # 'dynamic', 'shared', or 'grouped'\n",
    "SHOW_KDE = True    # Show KDE overlay\n",
    "SAVE_PLOTS = False  # Set to False to only display plots without saving\n",
    "\n",
    "# Filtering configuration\n",
    "config = {\n",
    "    'filter_overlaps': True,\n",
    "    'filter_retained_introns': True,\n",
    "    'filter_readthrough': True,\n",
    "    'filter_nmd': True,\n",
    "    'allowed_gene_biotypes': ['protein_coding'],\n",
    "    'allowed_transcript_biotypes': ['protein_coding'],\n",
    "    'filter_non_canonical': False,  # Set to True for canonical only\n",
    "    'min_transcript_support_level': None  # Set to 1-5 for TSL filtering\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c34fd-dd2c-4bc1-a9e8-6d026584f993",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b125d-56c0-4a44-99c5-6ed28cdd3208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading 8 parquet file(s)...\n",
      "  Loaded Dorado_filtered_20_20_17596.parquet -> Ino: 14 rows\n",
      "  Loaded Dorado_filtered_20_20_17802.parquet -> Psi: 2 rows\n",
      "  Loaded Dorado_filtered_20_20_19227.parquet -> 2OmethylU: 4 rows\n",
      "  Loaded Dorado_filtered_20_20_19228.parquet -> 2OmethylC: 1 rows\n",
      "  Loaded Dorado_filtered_20_20_19229.parquet -> 2OmethylG: 1 rows\n",
      "  Loaded Dorado_filtered_20_20_69426.parquet -> 2OmethylA: 1 rows\n",
      "  Loaded Dorado_filtered_20_20_a.parquet -> m6A: 106 rows\n",
      "  Loaded Dorado_filtered_20_20_m.parquet -> m5C: 44 rows\n",
      "\n",
      "Loaded 8 modification type(s): ['Ino', 'Psi', '2OmethylU', '2OmethylC', '2OmethylG', '2OmethylA', 'm6A', 'm5C']\n",
      "\n",
      "Parsing GTF file: gencode.v47.annotation.gtf\n",
      "Identifying transcripts to filter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading GTF: 4105490it [01:18, 52316.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 705 zero-width intervals\n",
      "Applying biotype filters...\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load parquet files\n",
    "df_dict = load_parquet_files(PARQUET_DIR)\n",
    "\n",
    "# Process GTF and calculate positions\n",
    "results, stats = process_gtf_and_calculate_positions(df_dict, GTF_PATH, config)\n",
    "\n",
    "# Save results for future use\n",
    "save_results(results, OUTPUT_DIR / 'results.pkl', stats)\n",
    "\n",
    "# Print statistics\n",
    "print_statistics(results, stats)\n",
    "\n",
    "# Create main plot\n",
    "plot_modifications(\n",
    "    results,\n",
    "    output_path=OUTPUT_DIR / 'rna_modifications_plot.pdf',\n",
    "    window_size=WINDOW_SIZE,\n",
    "    bin_width=BIN_WIDTH,\n",
    "    show_kde=SHOW_KDE,\n",
    "    y_axis_mode=Y_AXIS_MODE,\n",
    "    stats=stats,\n",
    "    save_plot=SAVE_PLOTS  # Uses the config setting\n",
    ")\n",
    "\n",
    "# Create combined plot\n",
    "plot_combined(\n",
    "    results,\n",
    "    output_path=OUTPUT_DIR / 'rna_modifications_combined.pdf',\n",
    "    window_size=WINDOW_SIZE,\n",
    "    bin_width=BIN_WIDTH,\n",
    "    stats=stats,\n",
    "    save_plot=SAVE_PLOTS  # Uses the config setting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23967ac6-be45-4a8f-b40c-e28a7916eb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
