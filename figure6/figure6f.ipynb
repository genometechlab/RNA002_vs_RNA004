{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d848a84-ccd8-46b5-be6e-2bf5422f2442",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4134cb5b-e300-4daf-b5b3-9242b433161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9853a3-67aa-4d27-b53b-c1864b255f2e",
   "metadata": {},
   "source": [
    "## Configuration and Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4a0700-517a-4be0-a088-66b6ed498ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "DORADO_FILE = Path('../Exemplar_Data/annotated_output/pickle_output/08_07_24_GM12878_chr12-112000000-114000000_annotated_valid_kmer.pkl')\n",
    "\n",
    "# DATA_URLS = {\n",
    "#     'glori1': 'https://static-content.springer.com/esm/art%3A10.1038%2Fs41592-025-02680-9/MediaObjects/41592_2025_2680_MOESM5_ESM.xlsb',\n",
    "#     'glori2': 'https://static-content.springer.com/esm/art%3A10.1038%2Fs41592-025-02680-9/MediaObjects/41592_2025_2680_MOESM3_ESM.xlsb'\n",
    "#     'm5c': 'https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE225614&format=file&file=GSE225614%5FHEK293T%2DWT%5Fsites%2Etsv%2Egz',\n",
    "#     'bid_seq': 'https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE179798&format=file&file=GSE179798_HEK293T_mRNA_WT_BID-seq.xlsx',\n",
    "#     'praise': 'https://static-content.springer.com/esm/art%3A10.1038%2Fs41589-023-01304-7/MediaObjects/41589_2023_1304_MOESM3_ESM.xlsx',\n",
    "#     # 'inosine': 'refer to figure 6c code'\n",
    "# }\n",
    "\n",
    "DATA_DIR = Path(\"../Exemplar_Data/orthogonal_data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for name, url in DATA_URLS.items():\n",
    "#     if url == 'YOUR_URL_HERE':\n",
    "#         continue\n",
    "#     output_file = DATA_DIR / Path(url).name\n",
    "#     if not output_file.exists():\n",
    "#         subprocess.run(['wget', '-q', '-O', str(output_file), url], check=True)\n",
    "\n",
    "M6A_GLORI1_FILE = DATA_DIR / \"41592_2025_2680_MOESM5_ESM.xlsb\"\n",
    "M6A_GLORI2_FILE = DATA_DIR / \"41592_2025_2680_MOESM3_ESM.xlsb\"\n",
    "M5C_FILE = DATA_DIR / \"GSE225614_HEK293T-WT_sites.tsv.gz\"\n",
    "PSI_BIDSEQ_FILE = DATA_DIR / \"GSE179798_HEK293T_mRNA_WT_BID-seq.xlsx\"\n",
    "PSI_PRAISE_FILE = DATA_DIR / \"41589_2023_1304_MOESM3_ESM.xlsx\"\n",
    "INO_FILE = DATA_DIR / \"Data_S2_A-to-I_sites_identified_by_slic-seq.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c57a7a-5128-4d16-86a8-fe10b4fbe884",
   "metadata": {},
   "source": [
    "## Color Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d42ab0b-6d50-49bc-945c-1f4deae490e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOD_COLORS = {\n",
    "    'm6A': '#0072B2',\n",
    "    'm5C': '#CC79A7',\n",
    "    'psi': '#D55E00',\n",
    "    'inosine': '#009E73'\n",
    "}\n",
    "\n",
    "MOD_CODES = {\n",
    "    'm6A': ['a'],\n",
    "    'm5C': ['m'],\n",
    "    'psi': ['17802', 'psi'],\n",
    "    'inosine': ['17596', 'inosine', 'I']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777015b6-6c9b-4b50-b19f-9a48fcbc74d3",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a18742d-cc1c-4fa2-a45f-9b9f85f27a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Any\n",
    "import gzip\n",
    "\n",
    "class OrthogonalDataloader:\n",
    "    def __init__(self, file_path: Union[Path, str]) -> None:\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.is_file():\n",
    "            raise FileNotFoundError(f\"File not found: '{self.file_path}'\")\n",
    "\n",
    "    def load_data(self, **kwargs: Any) -> Union[pd.DataFrame, dict, Any]:\n",
    "        suffixes = self.file_path.suffixes\n",
    "        compression = 'gzip' if '.gz' in suffixes else None\n",
    "        \n",
    "        try:\n",
    "            if '.xlsb' in suffixes or '.xlsx' in suffixes:\n",
    "                if 'sheet_name' not in kwargs:\n",
    "                    kwargs['sheet_name'] = None\n",
    "                engine = 'pyxlsb' if '.xlsb' in suffixes else None\n",
    "                return pd.read_excel(self.file_path, engine=engine, **kwargs)\n",
    "            elif '.csv' in suffixes:\n",
    "                return pd.read_csv(self.file_path, compression=compression, **kwargs)\n",
    "            elif '.tsv' in suffixes or '.txt' in suffixes:\n",
    "                if 'sep' not in kwargs:\n",
    "                    kwargs['sep'] = '\\t'\n",
    "                return pd.read_csv(self.file_path, compression=compression, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file type: {''.join(suffixes)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {self.file_path.name}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911fc3e1-da03-4637-81f8-347cc63cf83d",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e22a76-9c4d-43ad-801d-db57542b4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as pickle: 172 sites\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "def is_git_lfs_pointer(filepath):\n",
    "    \"\"\"Check if file is a Git LFS pointer\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "            return first_line.startswith('version https://git-lfs.github.com')\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def detect_and_load_file(filepath):\n",
    "    \"\"\"Detect file format and load appropriately\"\"\"\n",
    "    \n",
    "    if is_git_lfs_pointer(filepath):\n",
    "        raise ValueError(\n",
    "            f\"File {filepath} is a Git LFS pointer, not actual data!\\n\"\n",
    "            f\"Run 'git lfs pull' in your repository to download the actual file.\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        df = pl.read_parquet(filepath)\n",
    "        print(f\"Loaded as parquet: {len(df):,} sites\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df = pl.from_pandas(df)\n",
    "        print(f\"Loaded as gzipped pickle: {len(df):,} sites\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            df = pl.from_pandas(df)\n",
    "        print(f\"Loaded as pickle: {len(df):,} sites\")\n",
    "        return df\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        compression = 'gzip' if str(filepath).endswith('.gz') else None\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            filepath,\n",
    "            sep='\\t',\n",
    "            compression=compression,\n",
    "            header=None,\n",
    "            comment='#'\n",
    "        )\n",
    "        \n",
    "        if len(df.columns) >= 12:\n",
    "            df.columns = [\n",
    "                'chrom', 'drs_start', 'drs_end', 'name', 'score', 'strand',\n",
    "                'thick_start', 'thick_end', 'item_rgb', 'block_count', \n",
    "                'block_sizes', 'block_starts'\n",
    "            ] + [f'col_{i}' for i in range(12, len(df.columns))]\n",
    "        elif len(df.columns) >= 6:\n",
    "            df.columns = [\n",
    "                'chrom', 'drs_start', 'drs_end', 'name', 'score', 'strand'\n",
    "            ] + [f'col_{i}' for i in range(6, len(df.columns))]\n",
    "        else:\n",
    "            df.columns = [f'col_{i}' for i in range(len(df.columns))]\n",
    "        \n",
    "        if 'name' in df.columns and len(df) > 0:\n",
    "            sample_name = str(df['name'].iloc[0])\n",
    "            if '|' in sample_name:\n",
    "                name_parts = df['name'].str.split('|', expand=True)\n",
    "                if name_parts.shape[1] >= 4:\n",
    "                    df['gene_id'] = name_parts[0]\n",
    "                    df['gene_name'] = name_parts[1]\n",
    "                    df['mod'] = name_parts[2]\n",
    "                    df['feature_type'] = name_parts[3]\n",
    "        \n",
    "        df = pl.from_pandas(df)\n",
    "        print(f\"Loaded as BED: {len(df):,} sites\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"BED loading failed: {e}\")\n",
    "        pass\n",
    "    \n",
    "    raise ValueError(\n",
    "        f\"Could not load file {filepath}\\n\"\n",
    "        f\"Tried: parquet, pickle (gzipped and regular), and BED formats\"\n",
    "    )\n",
    "\n",
    "drs_df = detect_and_load_file(DORADO_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e731ec2e-f28a-48fc-a5c6-22b35ea20327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m6A validated: 108,822\n",
      "m5C validated: 2,191\n",
      "Psi validated: 2,114\n",
      "Inosine validated: 29,745\n"
     ]
    }
   ],
   "source": [
    "def process_orthogonal_sites(df, chr_col: str, pos_col: str):\n",
    "    if df is None:\n",
    "        return set()\n",
    "    sample_chr = str(df[chr_col].iloc[0]) if len(df) > 0 else None\n",
    "    pos_int = df[pos_col].astype(float).astype(int).astype(str)\n",
    "    if sample_chr and sample_chr.startswith('chr'):\n",
    "        sites = set(df[chr_col].astype(str) + '_' + pos_int)\n",
    "    else:\n",
    "        sites = set('chr' + df[chr_col].astype(str) + '_' + pos_int)\n",
    "    return sites\n",
    "\n",
    "loader = OrthogonalDataloader(M6A_GLORI1_FILE)\n",
    "glori1_raw = loader.load_data()\n",
    "if isinstance(glori1_raw, dict):\n",
    "    for sheet_name, df in glori1_raw.items():\n",
    "        if '10ng' in sheet_name:\n",
    "            glori1_df = df\n",
    "            break\n",
    "\n",
    "loader = OrthogonalDataloader(M6A_GLORI2_FILE)\n",
    "glori2_raw = loader.load_data()\n",
    "if isinstance(glori2_raw, dict):\n",
    "    for sheet_name, df in glori2_raw.items():\n",
    "        if '10ng' in sheet_name:\n",
    "            glori2_df = df\n",
    "            break\n",
    "\n",
    "glori1_sites = process_orthogonal_sites(glori1_df, 'Chr', 'Site')\n",
    "glori2_sites = process_orthogonal_sites(glori2_df, 'Chr', 'Site')\n",
    "m6a_validated = glori1_sites | glori2_sites\n",
    "\n",
    "loader = OrthogonalDataloader(M5C_FILE)\n",
    "m5c_raw = loader.load_data()\n",
    "m5c_df = m5c_raw[~(m5c_raw['gene_type'] == 'rRNA') & ~(m5c_raw['gene_type'] == 'tRNA')].copy()\n",
    "m5c_validated = process_orthogonal_sites(m5c_df, 'chromosome', 'position')\n",
    "\n",
    "loader = OrthogonalDataloader(PSI_BIDSEQ_FILE)\n",
    "bid_raw = loader.load_data()\n",
    "bid_df = bid_raw['Sheet1'] if isinstance(bid_raw, dict) else bid_raw\n",
    "bid_df.columns = bid_df.iloc[2]\n",
    "bid_df = bid_df[3:].reset_index(drop=True)\n",
    "\n",
    "loader = OrthogonalDataloader(PSI_PRAISE_FILE)\n",
    "praise_raw = loader.load_data()\n",
    "if isinstance(praise_raw, dict):\n",
    "    for sheet_name in praise_raw.keys():\n",
    "        if 'dataset 2' in sheet_name.lower():\n",
    "            praise_df = praise_raw[sheet_name]\n",
    "            break\n",
    "\n",
    "praise_df.columns = praise_df.iloc[1]\n",
    "praise_df = praise_df[2:].reset_index(drop=True)\n",
    "\n",
    "if 'chr_name' in praise_df.columns:\n",
    "    praise_df['accession'] = praise_df['chr_name'].astype(str)\n",
    "    praise_df = praise_df[\n",
    "        praise_df['accession'].str.startswith('NM_') | \n",
    "        praise_df['accession'].str.startswith('XM_')\n",
    "    ].copy()\n",
    "\n",
    "def parse_chr_site(chr_site_str):\n",
    "    try:\n",
    "        if pd.isna(chr_site_str):\n",
    "            return None, None\n",
    "        chr_site_str = str(chr_site_str).strip()\n",
    "        if '_' not in chr_site_str:\n",
    "            return None, None\n",
    "        parts = chr_site_str.split('_')\n",
    "        if len(parts) != 2:\n",
    "            return None, None\n",
    "        chrom = parts[0].strip()\n",
    "        pos_part = parts[1].strip()\n",
    "        if '-' in pos_part:\n",
    "            pos = pos_part.split('-')[0].strip()\n",
    "        else:\n",
    "            pos = pos_part.strip()\n",
    "        return chrom, int(pos)\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "if 'chr_site' in praise_df.columns:\n",
    "    parsed = praise_df['chr_site'].apply(parse_chr_site)\n",
    "    praise_df['chromosome'] = [x[0] for x in parsed]\n",
    "    praise_df['genomic_position'] = [x[1] for x in parsed]\n",
    "    praise_filtered = praise_df[\n",
    "        (praise_df['chromosome'].notna()) & \n",
    "        (praise_df['genomic_position'].notna())\n",
    "    ].copy()\n",
    "\n",
    "bid_sites = process_orthogonal_sites(bid_df, 'chr', 'pos')\n",
    "praise_sites = process_orthogonal_sites(praise_filtered, 'chromosome', 'genomic_position')\n",
    "psi_validated = bid_sites | praise_sites\n",
    "\n",
    "loader = OrthogonalDataloader(INO_FILE)\n",
    "ino_raw = loader.load_data()\n",
    "keep_locations = ['intergenic', 'exonic', 'UTR3', 'UTR5', 'UTR5;UTR3']\n",
    "ino_dfs = []\n",
    "for sheet_name, df in ino_raw.items():\n",
    "    if 'HEK293T-rep' in sheet_name:\n",
    "        df_filtered = df[df['Location'].isin(keep_locations)].copy()\n",
    "        ino_dfs.append(df_filtered)\n",
    "combined_ino = pd.concat(ino_dfs, ignore_index=True)\n",
    "ino_validated = process_orthogonal_sites(combined_ino, 'Chromosome', 'position')\n",
    "\n",
    "print(f\"m6A validated: {len(m6a_validated):,}\")\n",
    "print(f\"m5C validated: {len(m5c_validated):,}\")\n",
    "print(f\"Psi validated: {len(psi_validated):,}\")\n",
    "print(f\"Inosine validated: {len(ino_validated):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd44ba5-d3d4-46d9-b953-858f93497c12",
   "metadata": {},
   "source": [
    "## Filter DRS to Validated Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9d702a-d110-4fc4-b218-211020bd4dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DRS to validated sites: 51\n"
     ]
    }
   ],
   "source": [
    "if 'site_id' not in drs_df.columns:\n",
    "    drs_df = drs_df.with_columns([\n",
    "        (pl.col('chrom').cast(pl.Utf8) + '_' + \n",
    "         pl.col('drs_end').cast(pl.Int64).cast(pl.Utf8)).alias('site_id')\n",
    "    ])\n",
    "\n",
    "all_validated = m6a_validated | m5c_validated | psi_validated | ino_validated\n",
    "drs_df = drs_df.filter(pl.col('site_id').is_in(list(all_validated)))\n",
    "\n",
    "print(f\"Filtered DRS to validated sites: {len(drs_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2ea32-7e69-4f49-a762-8c5dc975eb66",
   "metadata": {},
   "source": [
    "## Find Multi-Mod Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b3b928-44e5-41a9-86b7-1617ef52d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding genes with multiple modifications...\n",
      "  m6A: 12 genes\n",
      "  m5C: 0 genes\n",
      "  psi: 0 genes\n",
      "  inosine: 1 genes\n",
      "\n",
      "Three-way combinations:\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding genes with multiple modifications...\")\n",
    "\n",
    "validated_genes = {mod_type: set() for mod_type in MOD_CODES.keys()}\n",
    "\n",
    "for mod_type, codes in MOD_CODES.items():\n",
    "    codes_str = [str(c) for c in codes]\n",
    "    \n",
    "    if mod_type == 'm6A':\n",
    "        validated_sites = m6a_validated\n",
    "    elif mod_type == 'm5C':\n",
    "        validated_sites = m5c_validated\n",
    "    elif mod_type == 'psi':\n",
    "        validated_sites = psi_validated\n",
    "    else:\n",
    "        validated_sites = ino_validated\n",
    "    \n",
    "    drs_mod = drs_df.filter(pl.col('mod').cast(pl.Utf8).is_in(codes_str))\n",
    "    matched = drs_mod.filter(pl.col('site_id').is_in(list(validated_sites)))\n",
    "    gene_ids = set(matched['gene_id'].unique().to_list())\n",
    "    gene_ids.discard(None)\n",
    "    validated_genes[mod_type] = gene_ids\n",
    "    \n",
    "    print(f\"  {mod_type}: {len(gene_ids)} genes\")\n",
    "\n",
    "three_way_combos = {\n",
    "    'm6A_m5C_psi': validated_genes['m6A'] & validated_genes['m5C'] & validated_genes['psi'],\n",
    "    'm6A_m5C_inosine': validated_genes['m6A'] & validated_genes['m5C'] & validated_genes['inosine'],\n",
    "    'm6A_psi_inosine': validated_genes['m6A'] & validated_genes['psi'] & validated_genes['inosine'],\n",
    "    'm5C_psi_inosine': validated_genes['m5C'] & validated_genes['psi'] & validated_genes['inosine']\n",
    "}\n",
    "\n",
    "print(\"\\nThree-way combinations:\")\n",
    "for combo_name, genes in three_way_combos.items():\n",
    "    if len(genes) > 0:\n",
    "        print(f\"  {combo_name}: {len(genes)} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1005bb-d938-4a5d-bcf6-7848f837a7c4",
   "metadata": {},
   "source": [
    "## Create Gene Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b164bf3-b265-4dc2-8152-7abf38187b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No multi-modification genes found\n"
     ]
    }
   ],
   "source": [
    "def create_gene_details(drs_df, gene_sets, combinations):\n",
    "    gene_details_list = []\n",
    "    \n",
    "    for combo_name in combinations:\n",
    "        if combo_name not in gene_sets or len(gene_sets[combo_name]) == 0:\n",
    "            continue\n",
    "        \n",
    "        mods = combo_name.split('_')\n",
    "        \n",
    "        for gene_id in gene_sets[combo_name]:\n",
    "            gene_data = drs_df.filter(pl.col('gene_id') == gene_id)\n",
    "            \n",
    "            if len(gene_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            gene_name = gene_data['gene_name'][0]\n",
    "            chrom = gene_data['chrom'][0]\n",
    "            strand = gene_data['strand'][0]\n",
    "            \n",
    "            mod_counts = {}\n",
    "            for mod in mods:\n",
    "                if mod not in MOD_CODES:\n",
    "                    continue\n",
    "                mod_sites = gene_data.filter(pl.col('mod').cast(pl.Utf8).is_in([str(c) for c in MOD_CODES[mod]]))\n",
    "                mod_counts[mod] = len(mod_sites)\n",
    "            \n",
    "            min_pos = gene_data['drs_start'].min()\n",
    "            max_pos = gene_data['drs_end'].max()\n",
    "            \n",
    "            gene_details_list.append({\n",
    "                'gene_id': gene_id,\n",
    "                'gene_name': gene_name,\n",
    "                'chromosome': chrom,\n",
    "                'strand': strand,\n",
    "                'start': min_pos,\n",
    "                'end': max_pos,\n",
    "                'span_kb': round((max_pos - min_pos) / 1000, 2),\n",
    "                'combination': combo_name,\n",
    "                'modifications': ','.join(mods),\n",
    "                **{f'n_{mod}_sites': mod_counts.get(mod, 0) for mod in mods},\n",
    "                'total_sites': sum(mod_counts.values())\n",
    "            })\n",
    "    \n",
    "    if len(gene_details_list) > 0:\n",
    "        return pl.DataFrame(gene_details_list).sort('total_sites', descending=True)\n",
    "    return None\n",
    "\n",
    "combinations_to_plot = [k for k, v in three_way_combos.items() if len(v) > 0]\n",
    "multi_mod_df = create_gene_details(drs_df, three_way_combos, combinations_to_plot)\n",
    "\n",
    "if multi_mod_df is not None:\n",
    "    print(f\"\\nFound {len(multi_mod_df)} genes with multiple modifications:\")\n",
    "    print(multi_mod_df)\n",
    "else:\n",
    "    print(\"\\nNo multi-modification genes found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ef999-1599-4470-8434-c59b844816af",
   "metadata": {},
   "source": [
    "## Create Swarm Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ec19c2-c596-4799-be6c-7a73f0ea5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No genes to plot\n"
     ]
    }
   ],
   "source": [
    "if multi_mod_df is None or len(multi_mod_df) == 0:\n",
    "    print(\"No genes to plot\")\n",
    "else:\n",
    "    combinations = multi_mod_df['combination'].unique().to_list()\n",
    "    \n",
    "    for combo_name in combinations:\n",
    "        print(f\"\\nPlotting {combo_name}...\")\n",
    "        \n",
    "        combo_genes = multi_mod_df.filter(\n",
    "            pl.col('combination') == combo_name\n",
    "        ).head(10)\n",
    "        \n",
    "        if len(combo_genes) == 0:\n",
    "            continue\n",
    "        \n",
    "        gene_list = combo_genes['gene_name'].to_list()\n",
    "        mods = combo_genes['modifications'][0].split(',')\n",
    "        \n",
    "        fig, axes = plt.subplots(len(gene_list), 1, \n",
    "                                figsize=(12, 3.5 * len(gene_list)))\n",
    "        if len(gene_list) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, gene_name in zip(axes, gene_list):\n",
    "            gene_data = drs_df.filter(pl.col('gene_name') == gene_name)\n",
    "            \n",
    "            if len(gene_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            strand = gene_data['strand'][0]\n",
    "            \n",
    "            plot_data = []\n",
    "            for mod_name in mods:\n",
    "                mod_sites = gene_data.filter(\n",
    "                    pl.col('mod').cast(pl.Utf8).is_in([str(c) for c in MOD_CODES[mod_name]])\n",
    "                )\n",
    "                \n",
    "                for row in mod_sites.iter_rows(named=True):\n",
    "                    plot_data.append({\n",
    "                        'position': row['drs_start'],\n",
    "                        'modification': mod_name\n",
    "                    })\n",
    "            \n",
    "            if len(plot_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            plot_df = pd.DataFrame(plot_data)\n",
    "            \n",
    "            sns.swarmplot(\n",
    "                data=plot_df,\n",
    "                x='position',\n",
    "                hue='modification',\n",
    "                palette=MOD_COLORS,\n",
    "                ax=ax,\n",
    "                size=6,\n",
    "                alpha=0.8,\n",
    "                hue_order=mods\n",
    "            )\n",
    "            \n",
    "            strand_symbol = '→' if strand == '+' else '←'\n",
    "            strand_text = f\"5' {strand_symbol} 3'\" if strand == '+' else f\"3' {strand_symbol} 5'\"\n",
    "            \n",
    "            ax.set_title(f\"{gene_name} ({strand} strand) | {strand_text}\", \n",
    "                       fontsize=14, fontweight='bold', pad=10)\n",
    "            ax.set_xlabel(\"Genomic Position (bp)\", fontsize=12)\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "            if strand == '-':\n",
    "                ax.invert_xaxis()\n",
    "            \n",
    "            ax.ticklabel_format(style='plain', axis='x')\n",
    "            ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "            \n",
    "            ax.legend(title='Modification', bbox_to_anchor=(1.02, 1), \n",
    "                     loc='upper left', frameon=True)\n",
    "            ax.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  Displayed {combo_name} swarm plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
